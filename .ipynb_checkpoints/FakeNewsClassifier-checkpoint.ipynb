{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Fake News\n",
    "Trying two distinct approaches. One that uses NLP and could take more processing time - this should give better accuracy. Also trying an approach beforehand that does not use NLP (at least no vectorization and such) and should give faster results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from abbreviations import schwartz_hearst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data - creating target column\n",
    "true = pd.read_csv(\"dataset/true.csv\")\n",
    "fake = pd.read_csv(\"dataset/fake.csv\")\n",
    "\n",
    "true['fake'] = 0\n",
    "fake['fake'] = 1\n",
    "\n",
    "dataset = true.append(fake, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a lot of fake news articles the titles contain capitalized words. This might be a function of fake news articles going a more sensationalist route. Let us try to take advantage of that. A pitfall is that titles also contain a lot of abbreviations that are capitalized. We need to find a way to work around that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['title_abbr_list'] = dataset['title'].str.findall(r\"([A-Z]{2,})\")      # capital words in title\n",
    "\n",
    "# these could be the full forms in the text of the article\n",
    "full_candidate_list_series = dataset['text'].str.findall(r\"((?:(?:[A-Z](?:[a-z]{1,}))(?:.[a-z]{1,3}.|.)){2,})\")\n",
    "dataset['text_abbr_list'] = \\\n",
    "                full_candidate_list_series.apply(lambda x: [''.join([c for c in a if c.isupper()]) for a in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shwartz-hearst algo to find abbreviations that are stated in text like - Central Intelligence Agency (CIA)\n",
    "def get_abbr_sh(text):\n",
    "    pairs = schwartz_hearst.extract_abbreviation_definition_pairs(doc_text = text)\n",
    "    return pairs\n",
    "\n",
    "def check_char_upper(c):\n",
    "    if c >= 'A' and c <= 'Z':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def fully_upper(x):\n",
    "    for c in x:\n",
    "        if check_char_upper(c) is False:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# dataset['sh'] = dataset['text'].apply(get_abbr_sh)\n",
    "\n",
    "# get all the abbreviations from corpus together\n",
    "list_of_dicts = dataset['text'].apply(get_abbr_sh).to_list()\n",
    "dicts = {k: v for d in list_of_dicts for k, v in d.items()}\n",
    "corpus_abbr_list = list(dicts.keys())\n",
    "corpus_abbr_list = [x for x in corpus_abbr_list if fully_upper(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of common abbreviations that can be present in titles of news articles\n",
    "# note that these might be overfitting the data - might not be advisable; also hardcoding (similar to stopwords)\n",
    "common_abbr_list = ['TV', 'MSNBC', 'BBC', 'NBC', 'ABC', 'CNBC', 'CBS', 'RIA', 'NTV', 'ESPN', 'NYT', 'WSJ', 'ET',\n",
    "                    'US', 'UK', 'USA', 'UN', 'VP', 'GOP', 'CEO', 'DC', 'HQ', 'WWI', 'WWII', 'WWIII', 'OK', 'FY',\n",
    "                    'JFK', 'NYSE', 'NYC', 'EST', 'EDT', 'PST', 'PDT', 'CST', 'CDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_abbr(row):\n",
    "    # retain capitalized words that cannot be eliminated as abbreviations\n",
    "    \n",
    "    abbr_list = row.title_abbr_list\n",
    "    abbr_list = [x for x in abbr_list if not eliminate_abbr(x, row.text_abbr_list, row.text)]\n",
    "    return abbr_list\n",
    "\n",
    "def eliminate_abbr(abbr, text_abbr_list, text):\n",
    "    # eliminate capitalized words from list if they seem to be abbreviations\n",
    "    \n",
    "    # if the full forms are appearing in the text\n",
    "    for text_abbr in text_abbr_list:\n",
    "        if abbr in text_abbr:\n",
    "            return True\n",
    "    \n",
    "    # if the capitalized word has appeared in the text repeatedly \n",
    "    if text.count(abbr) > 1:\n",
    "        return True\n",
    "    \n",
    "    # if they have been identified by shwartz-hearst algo as an abbreviation in the corpus\n",
    "    if abbr in corpus_abbr_list:\n",
    "        return True\n",
    "    \n",
    "    # if they are present in the stop-word like common abbreviation list\n",
    "    if abbr in common_abbr_list:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "capitalized_words = dataset.apply(find_abbr, axis = 1)\n",
    "dataset['has_cap_words'] = capitalized_words.str.len() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake\n",
       "0       83.0\n",
       "1    18734.0\n",
       "Name: has_cap_words, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('fake')['has_cap_words'].aggregate('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. This seems to be a good feature to have. We can see that as compared to the fake news articles, very few true news articles have capitalized words (that have not been identified as abbreviations) in the title. <br><br>\n",
    "Let us also have a look at the lengths of the titles and articles themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['title_length'] = dataset['title'].str.len()\n",
    "dataset['text_length'] = dataset['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1a219cbac8>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1a21d84c50>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['title_length'].hist(by = dataset['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1a217f4780>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1a218622e8>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.loc[dataset['text_length'] < 10000, 'text_length'].hist(by = dataset['fake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see promising signs - with the length of titles at least. The distribution of length of title is vastly different for fake and true news articles. This feature might also help predict whether an article is fake or true news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>fake</th>\n",
       "      <th>title_abbr_list</th>\n",
       "      <th>text_abbr_list</th>\n",
       "      <th>has_cap_words</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[RMM, FN, PDT, HFC, RJC, US, HR, HSPR, IR, MM,...</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>4659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PDT, JD, TDD, DC, IS, TDD, SC, HB, DD, JL, AC...</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>4077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[RPT, LG, DJSCRM, FN, WH, NYT, HR, FBI, TR, CS...</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>2789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[FBI, NYT]</td>\n",
       "      <td>[GP, HC, NYT, AD, FBI, BD, TWH, TNYT, DTEPAFS,...</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>2461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PDT, PSF, USPO, PO, PS, PS, PRC, JB, BN, TWP,...</td>\n",
       "      <td>False</td>\n",
       "      <td>69</td>\n",
       "      <td>5204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  fake title_abbr_list  \\\n",
       "0  December 31, 2017      0              []   \n",
       "1  December 29, 2017      0              []   \n",
       "2  December 31, 2017      0              []   \n",
       "3  December 30, 2017      0      [FBI, NYT]   \n",
       "4  December 29, 2017      0              []   \n",
       "\n",
       "                                      text_abbr_list  has_cap_words  \\\n",
       "0  [RMM, FN, PDT, HFC, RJC, US, HR, HSPR, IR, MM,...          False   \n",
       "1  [PDT, JD, TDD, DC, IS, TDD, SC, HB, DD, JL, AC...          False   \n",
       "2  [RPT, LG, DJSCRM, FN, WH, NYT, HR, FBI, TR, CS...          False   \n",
       "3  [GP, HC, NYT, AD, FBI, BD, TWH, TNYT, DTEPAFS,...          False   \n",
       "4  [PDT, PSF, USPO, PO, PS, PS, PRC, JB, BN, TWP,...          False   \n",
       "\n",
       "   title_length  text_length  \n",
       "0            64         4659  \n",
       "1            64         4077  \n",
       "2            60         2789  \n",
       "3            59         2461  \n",
       "4            69         5204  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And looking at the subject column, it can be seen that that column deterministically predicts between fake and true news. This wouldn't really be a feature that we would get in a real life scenario. No point introducing that in a model in that case. <br>\n",
    "Date also should not be giving any new information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politicsNews' 'worldnews']\n",
      "['News' 'politics' 'Government News' 'left-news' 'US_News' 'Middle-east']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.loc[dataset['fake'] == 0, 'subject'].unique())\n",
    "print(dataset.loc[dataset['fake'] == 1, 'subject'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us clean up the dataframe and split the data into train and test. <br>\n",
    "**IMPORTANT:** The test train split should have been done before all the rest above was done. In this way, the corpus abbreviation list has benefitted from data from the test set. In a real life scenario, split should have happened earlier and the feature engineering should have been repeated for train and test sets. But, I'm just too lazy to go up and change all of the code - especially since this is a simplistic model that wouldn't really be used when we have access to vectorizing the actual text of the article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake</th>\n",
       "      <th>has_cap_words</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>4659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>4077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>2789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>2461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>69</td>\n",
       "      <td>5204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fake  has_cap_words  title_length  text_length\n",
       "0     0          False            64         4659\n",
       "1     0          False            64         4077\n",
       "2     0          False            60         2789\n",
       "3     0          False            59         2461\n",
       "4     0          False            69         5204"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(['title', 'text', 'subject', 'date', 'title_abbr_list', \n",
    "              'text_abbr_list'], axis = 1, inplace = True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset[['has_cap_words', 'title_length', 'text_length']], \n",
    "                                                    dataset.fake, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_cap_words</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36335</th>\n",
       "      <td>True</td>\n",
       "      <td>82</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12384</th>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24419</th>\n",
       "      <td>False</td>\n",
       "      <td>77</td>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24740</th>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>3414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27039</th>\n",
       "      <td>False</td>\n",
       "      <td>87</td>\n",
       "      <td>2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44732</th>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>False</td>\n",
       "      <td>65</td>\n",
       "      <td>2680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "      <td>3288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35918 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_cap_words  title_length  text_length\n",
       "36335           True            82         1534\n",
       "12384          False            63          558\n",
       "24419          False            77         2062\n",
       "24740           True            77         3414\n",
       "27039          False            87         2732\n",
       "...              ...           ...          ...\n",
       "11284          False            64         1703\n",
       "44732          False            33          821\n",
       "38158           True            62         1891\n",
       "860            False            65         2680\n",
       "15795          False            89         3288\n",
       "\n",
       "[35918 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4233   97]\n",
      " [ 598 4052]]\n",
      "0.9226057906458798\n"
     ]
    }
   ],
   "source": [
    "logit_model = LogisticRegression(solver = 'lbfgs')\n",
    "logit_model.fit(x_train, y_train)                          \n",
    "\n",
    "y_pred = logit_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3888  442]\n",
      " [ 848 3802]]\n",
      "0.856347438752784\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 9)\n",
    "knn_model.fit(x_train, y_train)                          \n",
    "\n",
    "y_pred = knn_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4274   56]\n",
      " [ 741 3909]]\n",
      "0.9112472160356347\n"
     ]
    }
   ],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train, y_train)                          \n",
    "\n",
    "y_pred = gnb_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3932  398]\n",
      " [ 332 4318]]\n",
      "0.9187082405345212\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(x_train, y_train)                           \n",
    "\n",
    "y_pred = tree_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3989  341]\n",
      " [ 336 4314]]\n",
      "0.9246102449888641\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 50)\n",
    "rf_model.fit(x_train, y_train)                           \n",
    "\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad for an approach not even using the text information. Over 92% accuracy for random forest and logit models. Now, let us try moving onto using the text. \n",
    "## Approach 2\n",
    "Using only about 50% (20000 records) of the data for this approach for faster processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 11:53:14,696 : INFO : NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>tillerson to visit africa in first quarter of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>trump asked putin if allegations of russian me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25213</th>\n",
       "      <td>watch: hypocrite trump supporter gets buried ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37292</th>\n",
       "      <td>hysterical video: saturday night live does cnn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23283</th>\n",
       "      <td>breaking: c.i.a. knew russia wanted trump way...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  fake\n",
       "12955  tillerson to visit africa in first quarter of ...     0\n",
       "677    trump asked putin if allegations of russian me...     0\n",
       "25213   watch: hypocrite trump supporter gets buried ...     1\n",
       "37292  hysterical video: saturday night live does cnn...     1\n",
       "23283   breaking: c.i.a. knew russia wanted trump way...     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = pd.read_csv(\"dataset/true.csv\")\n",
    "fake = pd.read_csv(\"dataset/fake.csv\")\n",
    "\n",
    "true['fake'] = 0\n",
    "fake['fake'] = 1\n",
    "\n",
    "dataset = true.append(fake, ignore_index = True)\n",
    "\n",
    "# taking a smaller sample for faster processing\n",
    "dataset = dataset.sample(20000)\n",
    "\n",
    "# drop unnecessary columns, convert all text to lower case\n",
    "dataset['text'] = dataset['title'] + dataset['text']\n",
    "dataset.drop(columns = ['title', 'subject', 'date'], inplace = True)\n",
    "dataset['text'] = dataset['text'].str.lower()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37280</th>\n",
       "      <td>[video] hundreds of mormon fundamentalists sur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>georgia congressman being eyed for top trump h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20718</th>\n",
       "      <td>former guerrilla coalition gets mandate to for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>trump retains marc kasowitz as private attorne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10836</th>\n",
       "      <td>senate leader mcconnell says wait on replacing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  fake\n",
       "37280  [video] hundreds of mormon fundamentalists sur...     1\n",
       "7264   georgia congressman being eyed for top trump h...     0\n",
       "20718  former guerrilla coalition gets mandate to for...     0\n",
       "3597   trump retains marc kasowitz as private attorne...     0\n",
       "10836  senate leader mcconnell says wait on replacing...     0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split test and train sets\n",
    "train, test = train_test_split(dataset, test_size = 0.2, random_state = 42)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us vectorize the text, build a vocabulary, find features of the test set according to this vocabulary and make a new x_test using these features. Further, keep only the top 10000 most frequent vocabulary words. Later words have very less to offer as they are too infrequent and also takes up too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000017</th>\n",
       "      <th>00004</th>\n",
       "      <th>00007</th>\n",
       "      <th>0009</th>\n",
       "      <th>000938</th>\n",
       "      <th>000a</th>\n",
       "      <th>000after</th>\n",
       "      <th>...</th>\n",
       "      <th>zzjjpdaivn</th>\n",
       "      <th>zzqvyk8xif</th>\n",
       "      <th>zzsg90pbf6</th>\n",
       "      <th>zztaine</th>\n",
       "      <th>zzucqevt3m</th>\n",
       "      <th>zzzzaaaacccchhh</th>\n",
       "      <th>zzzzzzzz</th>\n",
       "      <th>émigré</th>\n",
       "      <th>état</th>\n",
       "      <th>žižek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00     000  0000  00000017  00004  00007  0009  000938  000a  000after  \\\n",
       "0  0.0  0.0000   0.0       0.0    0.0    0.0   0.0     0.0   0.0       0.0   \n",
       "1  0.0  0.0000   0.0       0.0    0.0    0.0   0.0     0.0   0.0       0.0   \n",
       "2  0.0  0.0305   0.0       0.0    0.0    0.0   0.0     0.0   0.0       0.0   \n",
       "3  0.0  0.0000   0.0       0.0    0.0    0.0   0.0     0.0   0.0       0.0   \n",
       "4  0.0  0.0000   0.0       0.0    0.0    0.0   0.0     0.0   0.0       0.0   \n",
       "\n",
       "   ...  zzjjpdaivn  zzqvyk8xif  zzsg90pbf6  zztaine  zzucqevt3m  \\\n",
       "0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "1  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "2  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "3  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "4  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "\n",
       "   zzzzaaaacccchhh  zzzzzzzz  émigré  état  žižek  \n",
       "0              0.0       0.0     0.0   0.0    0.0  \n",
       "1              0.0       0.0     0.0   0.0    0.0  \n",
       "2              0.0       0.0     0.0   0.0    0.0  \n",
       "3              0.0       0.0     0.0   0.0    0.0  \n",
       "4              0.0       0.0     0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 86690 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get features for train\n",
    "tf_idf_vectorizer = TfidfVectorizer(use_idf = True, stop_words = 'english')\n",
    "tf_idf_vector_features_train = tf_idf_vectorizer.fit_transform(train.text).toarray()\n",
    "\n",
    "# get vocabulary (all of it)\n",
    "vocab_items = {v: k for k, v in tf_idf_vectorizer.vocabulary_.items()}\n",
    "vocab = [vocab_items[i] for i in range(len(vocab_items))]\n",
    "\n",
    "# make a new x_test with the sparse matrix\n",
    "x_train = pd.DataFrame(tf_idf_vector_features_train, columns = vocab)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12th</th>\n",
       "      <th>realclearpolitics</th>\n",
       "      <th>streams</th>\n",
       "      <th>clan</th>\n",
       "      <th>venezuelans</th>\n",
       "      <th>policymakers</th>\n",
       "      <th>coin</th>\n",
       "      <th>biological</th>\n",
       "      <th>sekulow</th>\n",
       "      <th>winston</th>\n",
       "      <th>...</th>\n",
       "      <th>video</th>\n",
       "      <th>republican</th>\n",
       "      <th>house</th>\n",
       "      <th>state</th>\n",
       "      <th>people</th>\n",
       "      <th>obama</th>\n",
       "      <th>clinton</th>\n",
       "      <th>president</th>\n",
       "      <th>said</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.073775</td>\n",
       "      <td>0.070590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.07792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.032269</td>\n",
       "      <td>0.206941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.071872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056291</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.080274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   12th  realclearpolitics  streams  clan  venezuelans  policymakers  coin  \\\n",
       "0   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "1   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "2   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "3   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "4   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "\n",
       "   biological  sekulow  winston  ...    video  republican     house  state  \\\n",
       "0         0.0      0.0      0.0  ...  0.01472    0.000000  0.027455    0.0   \n",
       "1         0.0      0.0      0.0  ...  0.00000    0.073775  0.070590    0.0   \n",
       "2         0.0      0.0      0.0  ...  0.00000    0.000000  0.000000    0.0   \n",
       "3         0.0      0.0      0.0  ...  0.00000    0.000000  0.036859    0.0   \n",
       "4         0.0      0.0      0.0  ...  0.00000    0.071872  0.000000    0.0   \n",
       "\n",
       "     people    obama  clinton  president      said     trump  \n",
       "0  0.000000  0.00000      0.0   0.000000  0.008012  0.000000  \n",
       "1  0.000000  0.07792      0.0   0.051415  0.000000  0.158529  \n",
       "2  0.000000  0.00000      0.0   0.016896  0.000000  0.000000  \n",
       "3  0.000000  0.00000      0.0   0.013423  0.032269  0.206941  \n",
       "4  0.056291  0.00000      0.0   0.100178  0.080274  0.000000  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the most frequently occuring 10000 words in the sparse matrix\n",
    "most_freq_10000 = list(x_train.sum(axis = 0).sort_values()[-10000:].index)\n",
    "x_train = x_train[most_freq_10000]\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to do all the same pre-processing for the test set as well. We need to use the same vocabulary to get the features and we will use the same set of most common 10000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12th</th>\n",
       "      <th>realclearpolitics</th>\n",
       "      <th>streams</th>\n",
       "      <th>clan</th>\n",
       "      <th>venezuelans</th>\n",
       "      <th>policymakers</th>\n",
       "      <th>coin</th>\n",
       "      <th>biological</th>\n",
       "      <th>sekulow</th>\n",
       "      <th>winston</th>\n",
       "      <th>...</th>\n",
       "      <th>video</th>\n",
       "      <th>republican</th>\n",
       "      <th>house</th>\n",
       "      <th>state</th>\n",
       "      <th>people</th>\n",
       "      <th>obama</th>\n",
       "      <th>clinton</th>\n",
       "      <th>president</th>\n",
       "      <th>said</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035442</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030946</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>0.030262</td>\n",
       "      <td>0.052522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070104</td>\n",
       "      <td>0.074901</td>\n",
       "      <td>0.072051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011099</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   12th  realclearpolitics  streams  clan  venezuelans  policymakers  coin  \\\n",
       "0   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "1   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "2   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "3   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "4   0.0                0.0      0.0   0.0          0.0           0.0   0.0   \n",
       "\n",
       "   biological  sekulow  winston  ...     video  republican     house  \\\n",
       "0         0.0      0.0      0.0  ...  0.000000         0.0  0.000000   \n",
       "1         0.0      0.0      0.0  ...  0.000000         0.0  0.000000   \n",
       "2         0.0      0.0      0.0  ...  0.000000         0.0  0.032083   \n",
       "3         0.0      0.0      0.0  ...  0.000000         0.0  0.000000   \n",
       "4         0.0      0.0      0.0  ...  0.039561         0.0  0.000000   \n",
       "\n",
       "      state    people  obama  clinton  president      said     trump  \n",
       "0  0.000000  0.049706    0.0      0.0   0.000000  0.035442  0.000000  \n",
       "1  0.008015  0.000000    0.0      0.0   0.030946  0.024798  0.000000  \n",
       "2  0.030262  0.052522    0.0      0.0   0.070104  0.074901  0.072051  \n",
       "3  0.000000  0.007783    0.0      0.0   0.000000  0.011099  0.000000  \n",
       "4  0.000000  0.060398    0.0      0.0   0.000000  0.010766  0.000000  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector_features_test = tf_idf_vectorizer.transform(list(test.text)).toarray()\n",
    "x_test = pd.DataFrame(tf_idf_vector_features_test, columns = vocab)\n",
    "x_test = x_test[most_freq_10000]\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with building the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1852   32]\n",
      " [  53 2063]]\n",
      "0.97875\n"
     ]
    }
   ],
   "source": [
    "logit_model = LogisticRegression(solver = 'lbfgs')\n",
    "logit_model.fit(x_train, train.fake)\n",
    "\n",
    "y_pred = logit_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(test.fake, y_pred))\n",
    "print(accuracy_score(test.fake, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1684  200]\n",
      " [ 111 2005]]\n",
      "0.92225\n"
     ]
    }
   ],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train, train.fake)                          \n",
    "\n",
    "y_pred = gnb_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(test.fake, y_pred))\n",
    "print(accuracy_score(test.fake, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1872   12]\n",
      " [  17 2099]]\n",
      "0.99275\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(x_train, train.fake)                           \n",
    "\n",
    "y_pred = tree_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(test.fake, y_pred))\n",
    "print(accuracy_score(test.fake, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1870   14]\n",
      " [  19 2097]]\n",
      "0.99175\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 25)\n",
    "rf_model.fit(x_train, train.fake)                           \n",
    "\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(test.fake, y_pred))\n",
    "print(accuracy_score(test.fake, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach, though much slower and processing intensive, is giving better results. We have 99.3% accuracy with the decision tree model. <br><br>The accuracy scores could have been even better if we had used the entire dataset and if more words than 10000 were used as features for the different models. Further, adding the three features from before - the lengths of titles, text and the presence of capitalized words could probably improve the accuracy still further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
